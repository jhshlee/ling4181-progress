{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6d8d84a",
   "metadata": {},
   "source": [
    "#### Preparation\n",
    "\n",
    "Import relevant packages and read the text files.\n",
    "Each .txt file includes text from a single author, a, b, c respectively.\n",
    "The length of each .txt file is different, with \"author c\" being the shortest with about 15k words.\n",
    "Then, unnecessary line breaks are removed.\n",
    "<br>Since punctuation marks cannot be removed for an already split text, I revise the first cell like the following, creating 2 versions of a text - one with lowercase letters, and the other split and without punctuation marks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d066052d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import pandas as pd\n",
    "import collections\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a60e271",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Punctuation marks are deleted.\n",
      "Punctuation marks are deleted.\n",
      "Punctuation marks are deleted.\n",
      "text_X_orig is the original text with all lowercase letters, and text_X is prepared by removing punctuation marks and splitting it in word units.\n"
     ]
    }
   ],
   "source": [
    "text_a_orig = open('author_a.txt','r')\n",
    "text_a_orig = text_a_orig.read().replace(\"\\n\", \" \").lower()\n",
    "text_a = text_a_orig.translate(str.maketrans(\"\",\"\", string.punctuation))\n",
    "print(\"Punctuation marks are deleted.\")\n",
    "text_a = text_a.split()\n",
    "\n",
    "text_b_orig = open('author_b.txt','r')\n",
    "text_b_orig = text_b_orig.read().replace(\"\\n\", \" \").lower()\n",
    "text_b = text_b_orig.translate(str.maketrans(\"\",\"\", string.punctuation))\n",
    "print(\"Punctuation marks are deleted.\")\n",
    "text_b = text_b.split()\n",
    "\n",
    "text_c_orig = open('author_c.txt','r')\n",
    "text_c_orig = text_c_orig.read().replace(\"\\n\", \" \").lower()\n",
    "text_c = text_c_orig.translate(str.maketrans(\"\",\"\", string.punctuation))\n",
    "print(\"Punctuation marks are deleted.\")\n",
    "text_c = text_c.split()\n",
    "\n",
    "print(\"text_X_orig is the original text with all lowercase letters, and text_X is prepared by removing punctuation marks and splitting it in word units.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88dbe9e9",
   "metadata": {},
   "source": [
    "### Lexical Measurement\n",
    "#### type-token ratio\n",
    "First, I could calculate type-token ratio for each author."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e68fe167",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21654\n",
      "22897\n",
      "15234\n"
     ]
    }
   ],
   "source": [
    "print(len(text_a))\n",
    "print(len(text_b))\n",
    "print(len(text_c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb6a5e2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are  3560 , 3640 , 2287 types in each respective text and the type-token ratio is  0.1644 , 0.159 , 0.1501 respectively.\n"
     ]
    }
   ],
   "source": [
    "# number of types\n",
    "\n",
    "type_a = (len(set(text_a)))\n",
    "type_b = (len(set(text_b)))\n",
    "type_c = (len(set(text_c)))\n",
    "\n",
    "# type - token ratio\n",
    "def lexical_diversity(text):\n",
    "    return round(len(set(text))/len(text),4)\n",
    "\n",
    "lexical_diversity(text_a)\n",
    "lexical_diversity(text_b)\n",
    "lexical_diversity(text_c)\n",
    "\n",
    "print(\"There are \", type_a,\",\", type_b,\",\", type_c, \"types in each respective text and the type-token ratio is \", lexical_diversity(text_a), \",\", lexical_diversity(text_b), \",\", lexical_diversity(text_c), \"respectively.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f60e66cb",
   "metadata": {},
   "source": [
    "#### Simpson's D index\n",
    "Next, I wrote some codes that calculate \"Simpson's D\" index, which is one of the ways that were introduced in Savoy(2020) to measure vocabulary richness. The closer the value is to 0, the more diverse the vocabulary is.\n",
    "\n",
    "*n* is the size of the corpus - in other words, token size.<br>\n",
    "*VOC(r)* is the number of words(type) that appear exactly *r* times in the given text.\n",
    "\n",
    "This code works well except when *r*=*n*, in other words, when the given text has only one type. \n",
    "When this is the case, the code returns 0.0. I don't know what the problem is here, but since my sample texts are not going to have any such instance, I just added a couple of lines that tells the function to return 1 (which is what happens when *r*=*n*, since there is no vocabulary diversity)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c0edb76",
   "metadata": {},
   "source": [
    "First attempt looked like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd7c0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simpson_D_version1\n",
    "\n",
    "def simpson_D(text):\n",
    "    types = set(text)\n",
    "    n = len(text)\n",
    "    def VOC(r):\n",
    "        VOC = 0\n",
    "        for word in types:\n",
    "            if text.count(word) == r:\n",
    "                VOC += 1\n",
    "        return VOC\n",
    "    for r in range(1,n):\n",
    "        if sum(VOC(r) for r in range(1, n-1)) == 0:\n",
    "            return 1\n",
    "        else:\n",
    "            return sum(VOC(r) * (r**2 - r) / (n**2 - n) for r in range(1,n))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab8e6f2",
   "metadata": {},
   "source": [
    "print(simpson_D(text_a))\n",
    "print(simpson_D(text_b))\n",
    "print(simpson_D(text_c))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea8ce44",
   "metadata": {},
   "source": [
    "This works, but it took too long time to compute. I wrote another version:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1115aa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0070774527083991255\n",
      "0.00654202743748956\n",
      "0.00979478876975365\n"
     ]
    }
   ],
   "source": [
    "# Simpson_D_version2: Use text that have not already been split\n",
    "\n",
    "def simpson_D(text):\n",
    "    count = collections.Counter(text)\n",
    "    types = set(text)\n",
    "    n = len(text)\n",
    "    def VOC(r):\n",
    "        VOC = 0\n",
    "        for i in types: # i is a word(type)\n",
    "            if count.get(i) == r:\n",
    "                VOC += 1\n",
    "        return VOC\n",
    "    for r in range(1,n):\n",
    "        if sum(VOC(r) for r in range(1, n-1)) == 0:\n",
    "            return 1\n",
    "        else:\n",
    "            return sum(VOC(r) * (r**2 - r) / (n**2 - n) for r in range(1,n))\n",
    "\n",
    "print(simpson_D(text_a))\n",
    "print(simpson_D(text_b))\n",
    "print(simpson_D(text_c))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "803b1d68",
   "metadata": {},
   "source": [
    "#### Mean word length and word length distribution\n",
    "Next, I wanted to know mean word length and mean sentence length. <br>\n",
    "As for the sentence length, the pre-processing was going to be tedious, because of the kind of text my samples are: blog posts. <br>\n",
    "Blog posts typically have multiple small headers, which was not considered when the texts were collected. <br>\n",
    "Usually, we could imagine sentence borders are where full stops (.), exclamation marks (!), and question marks (?) appear. However, since these small headers are effectively titles for each small section and thus do not have such marks at the end, it is difficult to take them into account without manually marking or deleting them - which would defy the whole point of calculating with a computer. <br><br>\n",
    "Another method I thought of was to get sentences by defining a sentences as \"words between two (aforementioned) sentence-ending marks. But this does not help with the headers either, and I have no idea what this could mean to the sample size.\n",
    "\n",
    "Hence, I decided to just calculate mean word length. I took the first 5k words from each file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2efe48d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1217\n",
      "1306\n",
      "1140\n",
      "4.4192\n",
      "4.6376\n",
      "4.8154\n"
     ]
    }
   ],
   "source": [
    "text_a_5k = text_a[:5000]\n",
    "text_b_5k = text_b[:5000]\n",
    "text_c_5k = text_c[:5000]\n",
    "\n",
    "print(len(set(text_a_5k)))\n",
    "print(len(set(text_b_5k)))\n",
    "print(len(set(text_c_5k)))\n",
    "\n",
    "average_a = sum(len(word) for word in text_a_5k) / len(text_a_5k)\n",
    "average_b = sum(len(word) for word in text_b_5k) / len(text_b_5k)\n",
    "average_c = sum(len(word) for word in text_c_5k) / len(text_c_5k)\n",
    "\n",
    "print(average_a)\n",
    "print(average_b)\n",
    "print(average_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf27c11",
   "metadata": {},
   "source": [
    "One thing I am curious about, but haven't tried yet, is whether these values (simpson_D, mean word length, etc) change meaningfully depending on how many words the text contains. Since I already have the codes, it will be simple enough to try and check this: for example, I could take the first 5k, 10k, 15k and 20k words from text_a and see if there is any change in the **simpson_D** value, or if the value becomes stable after a certain threshold. I haven't done this yet, but it is on the list."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d49bc92",
   "metadata": {},
   "source": [
    "#### Lexical density\n",
    "Lexical density is the ratio between the number of lexical items (1-functional words) and the text length.\n",
    "\n",
    "For this I thought of creating a list of function words - articles, prepositions, conjunctions, pronouns, etc., and counting their numbers.\n",
    "\n",
    "\n",
    "Some comparative values were necessary: I followed Savoy(2020, p.30) where it said (and I paraphrase) that an LD value of around 0.3 for an oral production and around 0.4 and higher for writings are the norm.\n",
    "\n",
    "There were other measures that makes use of vocabulary, such as \"Big word index\" which refers to the percentage of words with 6 letters or more, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338b364e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "abb00938",
   "metadata": {},
   "source": [
    "### Distance-based method\n",
    "#### Burrow's Delta (Savoy 2020: 34-36)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af2921e1",
   "metadata": {},
   "source": [
    "Burrow's Delta considers 40-150 most frequent word types, and the style is reflected through the word choice. I will also consider 150 most frequent types(MFWs) first. I assume I could just change some numbers in the code to get more word types from the frequency list, I will check out if the results change meaningfully if I raise the threshold to, say, 300 or 500."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daad71e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e90a0044",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390a5f25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00edd7fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce3b639",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1945ed22",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
